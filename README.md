# Crowdfunding_ELT (Extract, Transform, Load)
## Overview:
For the ETL mini project, you will work with a partner to practice building an ETL pipeline using Python, Pandas, and either Python dictionary methods or regular expressions to extract and transform the data. After you transform the data, you'll create four CSV files and use the CSV file data to create an ERD and a table schema. Finally, youâ€™ll upload the CSV file data into a Postgres database.

## Summary
Using Python, Pandas, Jupyter Notebook, and a PostgreSQL database:

  - Extracted and transformed data from a large Excel file into smaller CSV files
  - Created a PostgreSQL database and tables by using an ERD
  - Loaded CSV files into a database
  - Ran queries to retrieve data and generate reports for stakeholders

I planned the connections between the csv data files to prepare before loading the data into SQL:
![ETL_ERD](https://user-images.githubusercontent.com/116124181/214701948-d9901b41-fd04-4ac4-83e3-1bc259453704.png)

## Created the Category and Subcategory DataFrames:

![Category_ID](https://user-images.githubusercontent.com/116124181/214704370-90cf3f57-4a77-4f74-8675-cf7bb765b240.png)
![Subcategory_id](https://user-images.githubusercontent.com/116124181/214704373-cf064028-449f-4e52-a003-9203c1dc8261.png)

## Cleaned dataframe/csv file; Contacts:
![Contact_id](https://user-images.githubusercontent.com/116124181/214707197-62a02d13-2105-41ea-a111-f8d63c6170f3.png)
